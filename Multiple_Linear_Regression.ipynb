{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RwjxkSQAv_0"
      },
      "outputs": [],
      "source": [
        "#SECTION-1 :: EDA - Exploratory data analysis\n",
        "#Importing required libraries:\n",
        "import pandas as pd;\n",
        "import sklearn;\n",
        "import statsmodels.api as sm;\n",
        "import matplotlib.pyplot as plt;\n",
        "import seaborn as sns;\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor;\n",
        "from sklearn.model_selection import train_test_split;\n",
        "from sklearn.preprocessing import MinMaxScaler;\n",
        "from sklearn.metrics import r2_score;\n",
        "\n",
        "data = pd.read_csv('/content/day.csv');\n",
        "#Standardizing the date to a common format\n",
        "data['dteday'] = data['dteday'].str.replace(\"/\",\"-\");\n",
        "#Basis business/domain understanding few columns which are not needed for analysis can be dropped\n",
        "columns_to_drop = ['instant', 'dteday', 'mnth', 'weekday'];\n",
        "data = data.drop(columns=columns_to_drop);\n",
        "#Mapping numerical labels into categorical string values for 'season' & 'weathersit'\n",
        "replacement_map_season = {1: 'spring', 2: 'summer', 3: 'fall', 4: 'winter'};\n",
        "replacement_map_weathersit = {1: 'clear', 2: 'cloudy', 3: 'light_rain'};\n",
        "data['season'] = data['season'].replace(replacement_map_season);\n",
        "data['weathersit'] = data['weathersit'].replace(replacement_map_weathersit);\n",
        "\n",
        "#SECTION-2 :: Dummy variable creation for 'season' and 'weathersit' dropping first redundant dummy\n",
        "status_season = pd.get_dummies(data['season'], drop_first = True);\n",
        "status_weathersit = pd.get_dummies(data['weathersit'], drop_first = True);\n",
        "#Concat the dummy DF with the original one:\n",
        "data = pd.concat([data, status_season, status_weathersit], axis=1);\n",
        "#Dropping those categorical variables for which dummies are created\n",
        "data = data.drop('season',axis=1);\n",
        "data = data.drop('weathersit',axis=1);\n",
        "\n",
        "#SECTION-3: Train-Test data split:\n",
        "#Splitted in the ratio of 70:30 i.e 70 % dataset is used to train the model\n",
        "df_train,df_test = train_test_split(data, train_size=0.7, random_state=100);\n",
        "\n",
        "#SECTION-4: Feature scaling [Min-Max scaling as it can take care of the outliers if any]:\n",
        "#Instantiate the object\n",
        "scaler = MinMaxScaler();\n",
        "#Fit on the data [numeric variables only] by creating the list of numeric variables:\n",
        "num_vars = ['temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered' , 'cnt'];\n",
        "df_train[num_vars] = scaler.fit_transform(df_train[num_vars]);\n",
        "\n",
        "#SECTION-5: Model building i.e Training the model\n",
        "#Build the model with all the variables:\n",
        "y_train = df_train.pop('cnt');\n",
        "X_train = df_train;\n",
        "X_train_sm = sm.add_constant(X_train);\n",
        "lr = sm.OLS(y_train, X_train_sm);\n",
        "lr_model = lr.fit();\n",
        "print(lr_model.summary());\n",
        "#Create a dataframe that will contain the features along with their respective VIFs:\n",
        "vif = pd.DataFrame();\n",
        "vif['Features'] = X_train.columns;\n",
        "vif['VIF'] = [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])];\n",
        "vif['VIF'] = round(vif['VIF'] , 2);\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False);\n",
        "print(vif);\n",
        "#Ideal situation is p-value < 0.05 and VIF < 5:\n",
        "# --SET-1 Variables that can be dropped because of high p-value & high VIF ::\n",
        "#      temp, atemp, hum, workingday, yr\n",
        "# --SET-2 Variables that can be dropped because of high p-value & low VIF ::\n",
        "#      spring, summer, winter, cloudy, light_rain\n",
        "# --SET-3 Variables that can be dropped because of low p-value & high VIF ::\n",
        "#      windspeed, casual, registered\n",
        "# --SET-4 Variables that is to be kept because of low p-value & low VIF ::\n",
        "#      holiday\n",
        "\n",
        "#Dropping variables one by one from SET-1 iteratively from each observations:\n",
        "# dropping 'temp' as it has high p-value and high VIF\n",
        "X1 = X_train.drop('temp', axis=1);\n",
        "X1_train_sm = sm.add_constant(X1);\n",
        "lr = sm.OLS(y_train, X1_train_sm);\n",
        "lr_model = lr.fit();\n",
        "print(lr_model.summary());\n",
        "\n",
        "vif = pd.DataFrame();\n",
        "vif['Features'] = X1.columns;\n",
        "vif['VIF'] = [variance_inflation_factor(X1.values,i) for i in range(X1.shape[1])];\n",
        "vif['VIF'] = round(vif['VIF'] , 2);\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False);\n",
        "print(vif);\n",
        "\n",
        "# dropping 'workingday' as it has high p-value & high VIF from previous iteration\n",
        "X2 = X1.drop('workingday', axis=1);\n",
        "X2_train_sm = sm.add_constant(X2);\n",
        "lr = sm.OLS(y_train, X2_train_sm);\n",
        "lr_model = lr.fit();\n",
        "print(lr_model.summary());\n",
        "\n",
        "vif = pd.DataFrame();\n",
        "vif['Features'] = X2.columns;\n",
        "vif['VIF'] = [variance_inflation_factor(X2.values,i) for i in range(X2.shape[1])];\n",
        "vif['VIF'] = round(vif['VIF'] , 2);\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False);\n",
        "print(vif);\n",
        "\n",
        "# dropping 'yr' as it has high p-value & high VIF from previous iteration\n",
        "X3 = X2.drop('yr', axis=1);\n",
        "X3_train_sm = sm.add_constant(X3);\n",
        "lr = sm.OLS(y_train, X3_train_sm);\n",
        "lr_model = lr.fit();\n",
        "print(lr_model.summary());\n",
        "\n",
        "vif = pd.DataFrame();\n",
        "vif['Features'] = X3.columns;\n",
        "vif['VIF'] = [variance_inflation_factor(X3.values,i) for i in range(X3.shape[1])];\n",
        "vif['VIF'] = round(vif['VIF'] , 2);\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False);\n",
        "print(vif);\n",
        "\n",
        "# dropping 'atemp' as it has high p-value & high VIF from previous iteration\n",
        "X4 = X3.drop('atemp', axis=1);\n",
        "X4_train_sm = sm.add_constant(X4);\n",
        "lr = sm.OLS(y_train, X4_train_sm);\n",
        "lr_model = lr.fit();\n",
        "print(lr_model.summary());\n",
        "\n",
        "vif = pd.DataFrame();\n",
        "vif['Features'] = X4.columns;\n",
        "vif['VIF'] = [variance_inflation_factor(X4.values,i) for i in range(X4.shape[1])];\n",
        "vif['VIF'] = round(vif['VIF'] , 2);\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False);\n",
        "print(vif);\n",
        "\n",
        "# dropping 'windspeed' as it has high p-value & low VIF from previous iteration\n",
        "X5 = X4.drop('windspeed', axis=1);\n",
        "X5_train_sm = sm.add_constant(X5);\n",
        "lr = sm.OLS(y_train, X5_train_sm);\n",
        "lr_model = lr.fit();\n",
        "print(lr_model.summary());\n",
        "\n",
        "vif = pd.DataFrame();\n",
        "vif['Features'] = X5.columns;\n",
        "vif['VIF'] = [variance_inflation_factor(X5.values,i) for i in range(X5.shape[1])];\n",
        "vif['VIF'] = round(vif['VIF'] , 2);\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False);\n",
        "print(vif);\n",
        "\n",
        "# dropping 'hum' as it has high p-value & high VIF from previous iteration\n",
        "X6 = X5.drop('hum', axis=1);\n",
        "X6_train_sm = sm.add_constant(X6);\n",
        "lr = sm.OLS(y_train, X6_train_sm);\n",
        "lr_model = lr.fit();\n",
        "print(lr_model.summary());\n",
        "\n",
        "vif = pd.DataFrame();\n",
        "vif['Features'] = X6.columns;\n",
        "vif['VIF'] = [variance_inflation_factor(X6.values,i) for i in range(X6.shape[1])];\n",
        "vif['VIF'] = round(vif['VIF'] , 2);\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False);\n",
        "print(vif);\n",
        "\n",
        "# dropping 'winter' as it has high p-value & low VIF from previous iteration\n",
        "X7 = X6.drop('winter', axis=1);\n",
        "X7_train_sm = sm.add_constant(X7);\n",
        "lr = sm.OLS(y_train, X7_train_sm);\n",
        "lr_model = lr.fit();\n",
        "print(lr_model.summary());\n",
        "\n",
        "vif = pd.DataFrame();\n",
        "vif['Features'] = X7.columns;\n",
        "vif['VIF'] = [variance_inflation_factor(X7.values,i) for i in range(X7.shape[1])];\n",
        "vif['VIF'] = round(vif['VIF'] , 2);\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False);\n",
        "print(vif);\n",
        "\n",
        "# dropping 'holiday' as it has high p-value & low VIF from previous iteration\n",
        "X8 = X7.drop('holiday', axis=1);\n",
        "X8_train_sm = sm.add_constant(X8);\n",
        "lr = sm.OLS(y_train, X8_train_sm);\n",
        "lr_model = lr.fit();\n",
        "print(lr_model.summary());\n",
        "\n",
        "vif = pd.DataFrame();\n",
        "vif['Features'] = X8.columns;\n",
        "vif['VIF'] = [variance_inflation_factor(X8.values,i) for i in range(X8.shape[1])];\n",
        "vif['VIF'] = round(vif['VIF'] , 2);\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False);\n",
        "print(vif);\n",
        "\n",
        "#Residual distribution curve:\n",
        "y_train_pred = lr_model.predict(X8_train_sm);\n",
        "print(y_train_pred);\n",
        "\n",
        "res = y_train - y_train_pred;\n",
        "sns.distplot(res);\n",
        "\n",
        "#SECTION-6: Making prediction from the model on the test dataset:\n",
        "# same list of numerical variables we captured earlier in num_vars & then fit on test data:\n",
        "df_test[num_vars] = scaler.transform(df_test[num_vars]);\n",
        "#print(df_test.head(3));\n",
        "y_test = df_test.pop('cnt');\n",
        "X_test = df_test;\n",
        "X_test_sm = sm.add_constant(X_test);\n",
        "X_test_sm = X_test_sm.drop(['temp','atemp','hum','winter','yr','holiday','workingday','windspeed'],axis=1);\n",
        "\n",
        "#Make predictions:\n",
        "y_test_pred = lr_model.predict(X_test_sm);\n",
        "print(y_test_pred);\n",
        "\n",
        "#SECTION-7: Evaluating the model\n",
        "r2_test = r2_score(y_true = y_test , y_pred = y_test_pred );\n",
        "print(r2_test);\n",
        "r2_train = r2_score(y_true = y_train , y_pred = y_train_pred );\n",
        "print(r2_train);\n",
        "# value = 1 which matches with r_squared value of training dataset too which means model is fine\n",
        "\n"
      ]
    }
  ]
}